# ClusterRole for cpu-policy-daemonset.
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cpu-policy-daemonset
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
      - patch
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - list
  - apiGroups:
      - apps
      - extensions
    resources:
      - daemonsets
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - pods/eviction
    verbs:
      - create


---

# ServiceAccount for cpu-policy daemonset.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cpu-policy-daemonset
  namespace: default
---
# Bind cpu-policy daemonset ServiceAccount with ClusterRole.
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: cpu-policy-daemonset
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cpu-policy-daemonset
subjects:
- kind: ServiceAccount
  name: cpu-policy-daemonset
  namespace: default
---
# Daemonset that will change cpuManagerPolicy to static.
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: cpu-policy
spec:
  selector:
    matchLabels:
      name: cpu-policy
  template:
    metadata:
      labels:
        name: cpu-policy
    spec:
      hostPID: true
      hostIPC: true
      serviceAccountName: cpu-policy-daemonset
      containers:
      - name: cpu-policy
        image: scylladb/kubectl:1.11.5
        imagePullPolicy: Always
        env:
          - name: NODE
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
        securityContext:
          privileged: true
        volumeMounts:
          - name: hostfs
            mountPath: /mnt/hostfs
            mountPropagation: Bidirectional
      volumes:
        - name: hostfs
          hostPath:
            path: /
        - name: dbus
          hostPath:
            path: /var/run/dbus
        - name: systemd
          hostPath:
            path: /run/systemd
        - name: systemctl
          hostPath:
            path: /bin/systemctl
        - name: system
          hostPath:
            path: /etc/systemd/system
        - name: usr
          hostPath:
            path: /usr
        - name: lib
          hostPath:
            path: /lib/systemd
        - name: lib-linux
          hostPath:
            path: /lib/systemd
---
# Daemonset that will group NUM_DISKS disks following the pattern '/dev/ssd{i}'
# into a raid0 array and mount that array onto RAID_DIR.
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: raid-local-disks
spec:
  selector:
    matchLabels:
      name: raid-local-disks
  template:
    metadata:
      labels:
        name: raid-local-disks
    spec:
      tolerations:
        - key: role
          operator: Equal
          value: scylla-clusters
          effect: NoSchedule
      containers:
      - name: raid-local-disks
        image: scylladb/raid-setup:0.1
        env:
          - name: RAID_DIR
            value: "/mnt/hostfs/mnt/raid-disks/disk0"
          - name: DISK_MNT_DIR_PREFIX
            value: "/mnt/hostfs/mnt/disks/ssd"
          - name: DISK_DEV_PREFIX
            value: "/dev/sd"
        command:
          - "/bin/bash"
          - "-c"
          - "--"
        args:
          - |
            set -e
            set -x

            # If the disk has already been created, sleep indefinitely
            if [ -b "/dev/md0" ]; then
                echo "raid array already created!"
                sleep infinity
            fi

            # Discover how many disks there are
            DISK_DEV_SUFFIX=(b c d e f g h i)
            MAX_NUM_DISKS=8
            NUM_DISKS=0
            declare -a DISKS
            for i in `seq 0 $((MAX_NUM_DISKS-1))`;
            do
                CURR_DISK="${DISK_DEV_PREFIX}${DISK_DEV_SUFFIX[$i]}"
                if [ ! -b "$CURR_DISK" ]; then
                  break
                fi
                DISKS[$i]="$CURR_DISK"
                NUM_DISKS=$((i+1))
            done

            if [ $NUM_DISKS -eq 0 ]; then
              echo "no local disks detected!"
              sleep infinity
            fi

            # Unmount disks from host filesystem
            for i in `seq 0 $((NUM_DISKS-1))`;
            do
                CURR_DISK=${DISKS[$i]}
                DISCARD_FLAG_PATH="/sys/block/${CURR_DISK#'/dev/'}/queue/discard_granularity"
                umount $CURR_DISK &> /dev/null || echo "Disk $CURR_DISK already unmounted."
                if [ "`cat $DISCARD_FLAG_PATH`" != "0" ]; then
                    blkdiscard $CURR_DISK || true
                fi
            done
            # Waits till udev reread device data
            udevadm settle
            # Create a raid array
            yes | mdadm --create /dev/md0 --force --level=0 -c1024 --raid-devices="$NUM_DISKS" "${DISKS[@]}"
            # Waits till udev reread md0 device data
            udevadm settle
            # Format the raid array as xfs
            mkfs.xfs /dev/md0

            # Mount the raid array in a predefined location
            mkdir -p $RAID_DIR
            mount -o noatime /dev/md0 $RAID_DIR
        securityContext:
          privileged: true
        volumeMounts:
        - name: hostfs
          mountPath: /mnt/hostfs
          mountPropagation: Bidirectional
      volumes:
      - name: hostfs
        hostPath:
          path: /
